### Helper Functions (Input Resolving)

def get_read(wcs):
    if wcs.k == str(config["correctionMinKmer"]):
        return "data/auxiliary/softClippedSeqs/{run}/{barcode}.fasta".format(**wcs)
    else:
        wcs.k = str(int(wcs.k) - config["correctionKmerStep"])
        return "data/auxiliary/corrections/{run}/{k}/{barcode}.fasta".format(**wcs)


def get_csv(wcs):
    if wcs.k == str(config["correctionMinKmer"]):
        return "data/auxiliary/softClippedSeqs/{run}/{barcode}.k{k}.csv".format(**wcs),
    else:
        wcs = dict(wcs)
        wcs["prev_k"]= str(int(wcs["k"]) - config["correctionKmerStep"])
        return "data/auxiliary/corrections/{run}/{prev_k}/{barcode}.k{k}.csv".format(**wcs),


rule count_jellyfish:
    input:
        reference = "{prefix}.fasta",
    output:
        countfile = "{prefix}.k{k}.jellyfish",
        csv = "{prefix}.k{k}.csv",
    params:
        k = lambda wcs: wcs.k,
    conda:
        '../envs/jellyfish.yaml',
    threads:
        48        
    log:
        'logs/jellyfish_count_{prefix}_k{k}.log',
    shell:
        "jellyfish count -s 100000 -t {threads} -m {params.k} -o {output.countfile} {input.reference} && jellyfish dump -c -o {output.csv} {output.countfile}"

rule generateDelKmers:
    input:
        "data/input/nCoV-2019.reference.k{k}.csv"
    output:
        "data/auxiliary/corrections/reference/delkmers_k{k}.txt"
    script:
        "../scripts/errorCorrection/genIndelKmers.py"


rule select_kmer:
    input:
        reads = lambda wcs: get_csv(wcs),
        reference = "data/input/nCoV-2019.reference.k{k}.csv",
        delKmers = 'data/auxiliary/corrections/reference/delkmers_k{k}.txt'
    output:
        kmerset = "data/auxiliary/corrections/{run}/{k}/{barcode}.kmerset.fasta",
    params:
        k = lambda wcs: wcs.k,
    log:
        'logs/select_kmer_{run}_{barcode}_{k}_dsk.log',
    script:
        '../scripts/errorCorrection/select_kmer.py'

        
rule asm_select_kmer:
    input:
        kmerset = "data/auxiliary/corrections/{run}/{k}/{barcode}.kmerset.fasta",
    output:
        asm = "data/auxiliary/corrections/{run}/{k}/{barcode}.unitigs.fa"
    params:
        outprefix = "data/auxiliary/corrections/{run}/{k}/{barcode}",
        k = lambda wcs: wcs.k
    conda:
        '../envs/bcalm.yaml'
    log:
        'logs/corrections/graph_first_{run}_{k}_{barcode}.log'
    threads:
        48
    shell:
        'bcalm -in {input.kmerset} -abundance-min 0 -kmer-size {params.k} -repartition-type 1 -minimizer-type 1 -nb-cores {threads} -out {params.outprefix}'


rule asm2graph:
    input:
        asm = "data/auxiliary/corrections/{run}/{k}/{barcode}.unitigs.fa"
    output:
        graph = "data/auxiliary/corrections/{run}/{k}/{barcode}.gfa"
    params:
        k = lambda wcs: wcs.k
    log:
        'logs/corrections/asm2graph_{run}_{k}_{barcode}.log'
    shell:
        'python3 scripts/pangenome/convertToGFA.py {input.asm} {output.graph} {params.k} 2> {log}'

        
rule correct_read:
    input:
        reads = lambda wcs: get_read(wcs),
        graph = "data/auxiliary/corrections/{run}/{k}/{barcode}.gfa"
    output:
        corrected = "data/auxiliary/corrections/{run}/{k}/{barcode}.fasta",
        alignment = "data/auxiliary/corrections/{run}/{k}/{barcode}.gaf"
    wildcard_constraints:
        barcode = "\d+"
    params:
        k = lambda wcs: wcs.k,
        correction_param = "--corrected-clipped-out" if config["correctionClip"] else "--corrected-out"
    conda:
        '../envs/graphaligner.yaml'
    threads:
        48
    log:
        'logs/corrections/corrections_{run}_{k}_{barcode}.log'
    shell:
        "GraphAligner -t {threads} -g {input.graph} -f {input.reads} {params.correction_param} {output.corrected} --alignments-out {output.alignment} -x dbg --seeds-minimizer-length {params.k} 2> {log}"
