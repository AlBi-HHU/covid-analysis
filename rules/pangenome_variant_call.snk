rule map_read_pangenome:
    input:
        graph = "data/auxiliary/pangenome/pangenome.gfa",
        reads = "data/auxiliary/softClippedSeqs/{method}/{run}/{barcode}.fasta",
        
    output:
        mappings = "data/auxiliary/pangenome_vc/{method}/{run}/{barcode}/reads.gaf",

    conda:
        '../envs/graphaligner.yaml',

    threads:
        48
                
    log:
        'logs/pangenome_vc_read_mapping_{method}_{run}_{barcode}.log',

    shell:
        "GraphAligner -t {threads} -g {input.graph} -f {input.reads} -a {output.mappings} 2> {log}"


rule map_ref_pangenome:
    input:
        graph = "data/auxiliary/pangenome/pangenome.gfa",
        ref = "data/input/nCoV-2019.reference.fasta",
        
    output:
        mappings = "data/auxiliary/pangenome_vc/reference.gaf",

    conda:
        '../envs/graphaligner.yaml',

    threads:
        48
                
    log:
        'logs/pangenome_vc_reference_mapping.log',

    shell:
        "GraphAligner -t {threads} -g {input.graph} -f {input.ref} -a {output.mappings} 2> {log}"

rule node_pos_on_ref:
    input:
        graph = "data/auxiliary/pangenome/pangenome.gfa",
        mappings = "data/auxiliary/pangenome_vc/reference.gaf",

    output:
        node_pos_on_ref = "data/auxiliary/pangenome_vc/node2pos.csv"

    script:
        "../scripts/pangenome/node2pos.py"
        
rule call_variant:
    input:
        pangenome = "data/auxiliary/pangenome/pangenome.gfa",
        reads = "data/auxiliary/pangenome_vc/{method}/{run}/{barcode}/reads.gaf",
        node2pos = "data/auxiliary/pangenome_vc/node2pos.csv"

    output:
        variant = "data/auxiliary/pangenome_vc/{method}/{run}/{barcode}/variant.vcf.ugly",

    params:
        rvt = config["pangenomeRVTThreshold"]
        
    log:
        'logs/pangenome_vc_call_variant_{method}_{run}_{barcode}.log',

    script:
        "../scripts/pangenome/call_variant.py"

        
rule filter_same_pos_variant:
    input:
        "data/auxiliary/pangenome_vc/{method}/{run}/{barcode}/variant.vcf"

    output:
        "data/auxiliary/pangenome_vc/{method}/{run}/{barcode}/filter.vcf"

    conda:
        '../envs/freebayes.yaml',

    script:
        '../scripts/pangenome/clean_variant.py'
    
### Debug / Evaluation Only

def getAllVcfTuples(wildcards):
    all_vcfs = []

    for run in runs:
        for barcode in barcodes[run]:
            for method in methods: #TODO: Maybe remove this as this is confusing, methods refers to distinct separate samples here
                all_vcfs += [
                        'data/input/'+run+'/barcode'+barcode+'.{method}.' + vcf_suffix, #This method remains a wildcard for the comparison
                        'data/auxiliary/pangenome_vc/'+method+'/'+run+'/'+barcode+'/filter.vcf',
                        'data/auxiliary/pileupAnalysis/'+method+'/'+run+'/'+barcode+'.pileupanalysis.txt'
                    ]

    return all_vcfs

rule evaluate_vs_method:
    input:
        vcfs = getAllVcfTuples
    output:
        'data/output/evaluation/summary_{method}.info'
    conda:
        '../envs/vcfpy.yaml'
    script:
        '../scripts/vcfdiff_summary.py'

# TODO: Make file dynamic in config, move this parsing elsewhere?
gisaidMapping = {}
with open('data/input/mappingRunsGisaid.csv', 'r') as infile:
    lines = infile.read().splitlines()
    for l in lines:
        data = l.split()
        run = data[0]
        barcode = data[1]
        file = data[2]
        if not run in mapping:
            mapping[run] = {}
        mapping[run][barcode] = file



def getManualCurationTuples(wildcards):
    all_vcfs = []

    for run in runs:
        for barcode in barcodes[run]:
            for method in methods: #TODO: Maybe remove this as this is confusing, methods refers to distinct separate samples here
                all_vcfs += [
                        'data/input/gisaid/'+mapping[run][barcode], #This method remains a wildcard for the comparison
                        'data/auxiliary/pangenome_vc/'+method+'/'+run+'/'+barcode+'/filter.vcf',
                        'data/auxiliary/pileupAnalysis/'+method+'/'+run+'/'+barcode+'.pileupanalysis.txt'
                    ]

    return all_vcfs
    
rule evaluate_vs_manual:
    input:
        getManualCurationCombos
    output:
        'data/output/evaluation/summary_manual.info'
    conda:
        '../envs/vcfpy.yaml'
    script:
        '../scripts/vcfdiff_summary_manual.py'

all_vcfs = []
freebayes_vcfs = [expand('data/auxiliary/discovery/freebayes/{method}/{run}/' + str(config["pangenomeCorrectionK"]) + '/{barcode}.vcf', method=methods, barcode=barcodes[run], run=run) for run in runs]
freebayes_vcfs = [item for sublist in freebayes_vcfs for item in sublist]
all_vcfs += freebayes_vcfs
cortex_vcfs = [expand('data/auxiliary/discovery/cortex/{method}/{run}/' + str(config["pangenomeCorrectionK"]) + '/{barcode}.vcf', method=methods, barcode=barcodes[run], run=run) for run in runs]
cortex_vcfs = [item for sublist in cortex_vcfs for item in sublist]
all_vcfs += cortex_vcfs
original_vcfs = [expand('data/input/{run}/barcode{barcode}.{method}.'+vcf_suffix, method=methods, barcode=barcodes[run], run=run) for run in runs]
original_vcfs = [item for sublist in original_vcfs for item in sublist]
all_vcfs += original_vcfs

rule get_contributions:
    input:
        cortex_calls = cortex_vcfs,
        other_calls = list(set(all_vcfs) - set(cortex_vcfs)),
        filter_vcfs = [expand('data/auxiliary/pangenome_vc/{method}/{run}/{barcode}/filter.vcf', method=methods, barcode=barcodes[run], run=run) for run in runs]
    output:
        contrib = 'data/auxiliary/pangenome_vc/contrib.txt'
    conda:
        '../envs/vcfpy.yaml'
    script:
        '../scripts/getExclusiveCortex.py'
